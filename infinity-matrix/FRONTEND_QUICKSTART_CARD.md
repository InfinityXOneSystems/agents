# âš¡ QuickStart Reference Card

## ğŸš€ Start Everything (3 Steps)

### Step 1: Backend (Cloud AI)
```bash
cd c:\AI\infinity-matrix\ai_stack
python launch_all_agents.py
# Runs on port 3001
```

### Step 2: Local AI (Optional)
```bash
ollama serve
# In another terminal: ollama pull mistral
# Runs on port 11434
```

### Step 3: Frontend
```bash
cd c:\AI\infinity-matrix\frontend
npm run dev
# Opens http://localhost:3000
```

---

## ğŸŒ Test the Frontend

**URL**: http://localhost:3000/cloud-ai

**You'll see**:
- ğŸ”µ **Cloud AI Tab** (Vertex AI models)
- ğŸŸ¢ **Ollama Tab** (If Ollama running)

**Try**: 
1. Pick a model
2. Enter a prompt
3. Click "Process"
4. See results!

---

## ğŸ“‚ Key Files

| File | Purpose |
|------|---------|
| `frontend/src/pages/CloudAIPage.jsx` | Main dual-backend page |
| `frontend/src/lib/ollama-client.js` | Ollama API wrapper |
| `frontend/src/App.jsx` | Routes (includes /cloud-ai) |
| `frontend/.env.development` | Dev config (Cloud + Ollama) |
| `frontend/.env.production` | Prod config |

---

## ğŸ”§ Common Commands

```bash
# Frontend dev
cd frontend && npm run dev

# Frontend build
cd frontend && npm run build

# Ollama
ollama serve                    # Start server
ollama pull mistral             # Get a model
ollama list                     # See models
ollama pull llama2 neural-chat  # Get multiple

# Check if backends running
curl http://localhost:3001/cloud/health    # Cloud
curl http://localhost:11434/api/tags       # Ollama
```

---

## ğŸ¯ Architecture

```
Frontend (localhost:3000)
  â”œâ”€â”€ Cloud AI Tab â†’ Port 3001 (Vertex)
  â””â”€â”€ Ollama Tab â†’ Port 11434 (Local)
```

---

## âŒ Troubleshooting

| Issue | Fix |
|-------|-----|
| No Ollama tab | Start: `ollama serve` + `ollama pull mistral` |
| Backend error | Check port 3001 is running |
| Slow responses | Use smaller model: `ollama pull mistral` |
| High CPU | Reduce models or use lighter ones |

---

## ğŸ“š Read These

1. **FRONTEND_COMPLETE_SUMMARY.md** - Full overview
2. **OLLAMA_SETUP_GUIDE.md** - Ollama setup details
3. **FRONTEND_VERIFICATION.md** - Audit & checklist
4. **frontend/README.md** - Frontend-specific docs

---

## âœ… Verification

```bash
# Verify everything is ready
curl http://localhost:3001/cloud/health      # Cloud AI
curl http://localhost:11434/api/tags         # Ollama (if running)
curl http://localhost:3000                   # Frontend
```

---

## ğŸ‰ Status

**Frontend**: âœ… CLEAN & PRODUCTION-READY  
**Cloud AI Integration**: âœ… WORKING  
**Ollama Integration**: âœ… WORKING  
**Documentation**: âœ… COMPLETE

**Ready to deploy!** ğŸš€
